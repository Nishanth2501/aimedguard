# Processed Data Analysis - AI MedGuard

This folder contains exploratory data analysis (EDA) for the **cleaned, processed data**.

## Files

### Analysis Scripts

- **`eda_processed.py`** - Comprehensive EDA for all processed datasets
  - Analyzes clean parquet files
  - Validates data quality improvements
  - Confirms ML-readiness

- **`compare_raw_vs_processed.py`** - Comparison analysis
  - Shows before/after ETL transformations
  - Quantifies improvements
  - Validates data quality gains

### ðŸ“„ Output Files

Output reports will be generated in this folder when you run the scripts.

## How to Use

### Run Processed Data EDA
```bash
# From project root
cd /Users/nishanthreddypalugula/Projects/AiMedguard
python eda/processed_data_analysis/eda_processed.py > eda/processed_data_analysis/processed_eda_report.txt
```

### Run Comparison Analysis
```bash
python eda/processed_data_analysis/compare_raw_vs_processed.py > eda/processed_data_analysis/comparison_report.txt
```

## What This Analysis Reveals

### Claims Data (Processed)
- Clean parquet format with standardized names
- Columns: `npi`, `hcpcs`, `state`, `total_beneficiaries`, `avg_payment_amount`
- All numeric types properly typed (Int64, float64)
- No "Not Available" strings
- Ready for ML models

### Operational Data (Processed)
- 3 clean datasets:
  - **State Complications:** 1,120 records
  - **Timely & Effective Care:** 117,933 records
  - **Hospital Info:** 5,381 records
- Proper null handling
- Boolean columns correctly encoded
- Date fields parsed with period_key

### Compliance Data (Processed)
- PDF content chunked and indexed
- Ready for RAG/LLM applications
- Searchable text chunks with metadata

## Key Improvements from ETL

### Data Quality Gains:
1. Standardized column names (readable)
2. Proper data types (no mixed types)
3. Null handling (no string "Not Available")
4. Date parsing (datetime objects)
5. Format optimization (Parquet compression)
6. Schema validation (Pandera checks passed)
7. Feature engineering (period_key added)
8. Text standardization (trimmed, cleaned)

## Data Quality Score

**Raw Data:** 85/100  
**Processed Data:** 98/100  

### Improvements:
- Column naming: +5 points
- Data types: +5 points
- Null handling: +3 points

## Validation Status

All processed datasets pass schema validation:

```
claims.parquet - 9,660,647 rows validated
ops_state_complications.parquet - 1,120 rows validated
ops_timely_effective.parquet - 117,933 rows validated
ops_hospital_info.parquet - 5,381 rows validated
```

Run validation: `make validate_step2`

## ML Readiness

### Features Ready for Model Training:

**Claims Data:**
- Provider features: NPI, state, provider type
- Service features: HCPCS codes, place of service
- Volume features: Total beneficiaries, total services
- Financial features: Charges, payments, allowed amounts

**Operational Data:**
- Hospital characteristics: ID, location, services
- Quality metrics: Complication rates, mortality scores
- Performance indicators: Better/worse/same classifications
- Temporal features: Period keys for time-series analysis

**Compliance Data:**
- Text embeddings ready for RAG
- Chunked with overlap for context
- Metadata for filtering and search

## Next Steps

After reviewing processed data:
1. Feature engineering â†’ `ml/` folder
2. Model development â†’ `ml/` folder
3. API development â†’ `api/` folder
4. Dashboard creation â†’ `ui/` folder

---

**Analysis Status:** Ready to run  
**Data Quality:** High (98/100)  
**ML Ready:** Yes

